dis.boot.high <- matrix(data=NA, nrow=51, ncol=N)
state.rank <- matrix(data=NA, nrow=51, ncol=N)
N <- 20
J <- unique(ccap.data$state)
for (i in 1:N){
## Sample data in blocks by state
ccap.boot <- ccap.data[1,]
naes.boot <- naes.data[1,]
for (j in J){
ccap.state <- ccap.data[ccap.data$state==j,]
num <- table(ccap.data$state[ccap.data$state==j])
ccap.sample <- ccap.state[sample(1:nrow(ccap.state), size=num, replace=T, prob=ccap.data$pweight[ccap.data$state==j]), ]
ccap.boot <- rbind(ccap.boot, ccap.sample)
naes.state <- naes.data[naes.data$state.name==j,]
num <- table(naes.data$state.name[naes.data$state.name==j])
naes.sample <- naes.state[sample(1:nrow(naes.state), size=num, replace=T, prob=naes.data$pweight), ]
naes.boot <- rbind(naes.boot, naes.sample)
}
ccap.boot <- ccap.boot[-1,]
naes.boot <- naes.boot[-1,]
#####
##### Prejudice from CCAP #####
#####
## Subset to Asian, Hispanic, or White (N=17,825)
ccap.boot <- ccap.boot[ccap.boot$race=='White' | ccap.boot$race=='Asian' | ccap.boot$race=='Hispanic',]
## Create own group stereotype variables
ccap.boot$lazy.own <- ifelse(ccap.boot$race=='Asian', ccap.boot$lazy.asian,
ifelse(ccap.boot$race=='Hispanic', ccap.boot$lazy.hisp,
ifelse(ccap.boot$race=='White', ccap.boot$lazy.white, NA)))
ccap.boot$intel.own <- ifelse(ccap.boot$race=='Asian', ccap.boot$intel.asian,
ifelse(ccap.boot$race=='Hispanic', ccap.boot$intel.hisp,
ifelse(ccap.boot$race=='White', ccap.boot$intel.white, NA)))
## Calculate the difference between own group and black score
ccap.boot$lazy <- ccap.boot$lazy.own - ccap.boot$lazy.black
ccap.boot$intel <- ccap.boot$intel.own - ccap.boot$intel.black
## Aggregate the differences
ccap.boot$prejudice <- ccap.boot$lazy + ccap.boot$intel
## Standardize prejudice measure
ccap.boot$prej.stdz <- stdz(ccap.boot$prejudice)
#####
##### Prejudice from NAES #####
#####
## Subset to non black (N=19,325)
naes.boot <- naes.data[naes.data$race!=2,]
## Calculate the difference between own group and black score
naes.boot$hw <- naes.boot$work.oth - naes.boot$work.own
naes.boot$intel <- naes.boot$intel.oth - naes.boot$intel.own
naes.boot$trust <- naes.boot$trust.oth - naes.boot$trust.own
## Aggregate the three dummies
naes.boot$prejudice <- naes.boot$hw + naes.boot$intel + naes.boot$trust
## Standardize prejudice measure
naes.boot$prej.stdz <- stdz(naes.boot$prejudice)
## Combine prejudice measures
z <- data.frame(state.name=c(ccap.boot$state, naes.boot$state.name),
prej.stdz=c(ccap.boot$prej.stdz, naes.boot$prej.stdz))
## Proportion above ___
z$above <- ifelse(z$prej.stdz > mean(z$prej.stdz, na.rm=T), 1, 0)
z$high <- ifelse(z$prej.stdz > (mean(z$prej.stdz, na.rm=T) + sd(z$prej.stdz, na.rm=T)), 1, 0)
## Aggregate by state
a <- aggregate(prej.stdz~state.name, data=z, FUN=mean)
b <- aggregate(above~state.name, data=z, FUN=mean)
c <- aggregate(high~state.name, data=z, FUN=mean)
## Save output
dis.boot[,i] <- a$prej.stdz
dis.boot.above[,i] <- b$above
dis.boot.high[,i] <- c$high
## Create state rankings
state.rank[,i] <- 52-rank(dis.boot[,i])
}
rm(list=ls())
##########################################################################################
## BOOTSTRAPS FOR NAES / CCAP COMBINED
##########################################################################################
library(foreign)
set.seed(1977)
## Read in data
ccap.data <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/CCAP/ccap08-clean.csv', stringsAsFactors=F)
naes.data <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/NAES/naes08-online-clean-ALL.csv', stringsAsFactors=F)
naes.data <- naes.data[complete.cases(naes.data$wt.345),]
# Merge state.name in NAES (via fips)
state <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/NAES/08statevars.csv', stringsAsFactors=F)
naes.data <- merge(state, naes.data, by.x='state.fips', by.y='fips', all.x=T, all.y=F)
rm(state)
## Create probability weights (sum to 1)
ccap.data$pweight <- ccap.data$weight / sum(ccap.data$weight)
naes.data$pweight <- naes.data$wt.345 / sum(naes.data$wt.345, na.rm=T)
## Create empty data.frames to save bootstrap results
rank.mean <- data.frame(t01=rep(NA,7), t02=rep(NA,7), t03=rep(NA,7), t04=rep(NA,7),
t05=rep(NA,7), t06=rep(NA,7), t07=rep(NA,7), t08=rep(NA,7), t09=rep(NA,7), t10=rep(NA,7),
t11=rep(NA,7), t12=rep(NA,7), t13=rep(NA,7), t14=rep(NA,7), t15=rep(NA,7), t16=rep(NA,7),
t17=rep(NA,7), t18=rep(NA,7), t19=rep(NA,7), t20=rep(NA,7), t21=rep(NA,7), t22=rep(NA,7),
t23=rep(NA,7), t24=rep(NA,7), t25=rep(NA,7))
dis.boot <- matrix(data=NA, nrow=51, ncol=N)
dis.boot.above <- matrix(data=NA, nrow=51, ncol=N)
dis.boot.high <- matrix(data=NA, nrow=51, ncol=N)
state.rank <- matrix(data=NA, nrow=51, ncol=N)
N <- 20
J <- unique(ccap.data$state)
for (i in 1:N){
## Sample data in blocks by state
ccap.boot <- ccap.data[1,]
naes.boot <- naes.data[1,]
for (j in J){
ccap.state <- ccap.data[ccap.data$state==j,]
num <- table(ccap.data$state[ccap.data$state==j])
ccap.sample <- ccap.state[sample(1:nrow(ccap.state), size=num, replace=T,
prob=ccap.data$pweight[ccap.data$state==j]), ]
ccap.boot <- rbind(ccap.boot, ccap.sample)
naes.state <- naes.data[naes.data$state.name==j,]
num <- table(naes.data$state.name[naes.data$state.name==j])
naes.sample <- naes.state[sample(1:nrow(naes.state), size=num, replace=T,
prob=naes.data$pweight[naes.data$state.name==j]), ]
naes.boot <- rbind(naes.boot, naes.sample)
}
ccap.boot <- ccap.boot[-1,]
naes.boot <- naes.boot[-1,]
#####
##### Prejudice from CCAP #####
#####
## Subset to Asian, Hispanic, or White (N=17,825)
ccap.boot <- ccap.boot[ccap.boot$race=='White' | ccap.boot$race=='Asian' | ccap.boot$race=='Hispanic',]
## Create own group stereotype variables
ccap.boot$lazy.own <- ifelse(ccap.boot$race=='Asian', ccap.boot$lazy.asian,
ifelse(ccap.boot$race=='Hispanic', ccap.boot$lazy.hisp,
ifelse(ccap.boot$race=='White', ccap.boot$lazy.white, NA)))
ccap.boot$intel.own <- ifelse(ccap.boot$race=='Asian', ccap.boot$intel.asian,
ifelse(ccap.boot$race=='Hispanic', ccap.boot$intel.hisp,
ifelse(ccap.boot$race=='White', ccap.boot$intel.white, NA)))
## Calculate the difference between own group and black score
ccap.boot$lazy <- ccap.boot$lazy.own - ccap.boot$lazy.black
ccap.boot$intel <- ccap.boot$intel.own - ccap.boot$intel.black
## Aggregate the differences
ccap.boot$prejudice <- ccap.boot$lazy + ccap.boot$intel
## Standardize prejudice measure
ccap.boot$prej.stdz <- stdz(ccap.boot$prejudice)
#####
##### Prejudice from NAES #####
#####
## Subset to non black (N=19,325)
naes.boot <- naes.data[naes.data$race!=2,]
## Calculate the difference between own group and black score
naes.boot$hw <- naes.boot$work.oth - naes.boot$work.own
naes.boot$intel <- naes.boot$intel.oth - naes.boot$intel.own
naes.boot$trust <- naes.boot$trust.oth - naes.boot$trust.own
## Aggregate the three dummies
naes.boot$prejudice <- naes.boot$hw + naes.boot$intel + naes.boot$trust
## Standardize prejudice measure
naes.boot$prej.stdz <- stdz(naes.boot$prejudice)
## Combine prejudice measures
z <- data.frame(state.name=c(ccap.boot$state, naes.boot$state.name),
prej.stdz=c(ccap.boot$prej.stdz, naes.boot$prej.stdz))
## Proportion above ___
z$above <- ifelse(z$prej.stdz > mean(z$prej.stdz, na.rm=T), 1, 0)
z$high <- ifelse(z$prej.stdz > (mean(z$prej.stdz, na.rm=T) + sd(z$prej.stdz, na.rm=T)), 1, 0)
## Aggregate by state
a <- aggregate(prej.stdz~state.name, data=z, FUN=mean)
b <- aggregate(above~state.name, data=z, FUN=mean)
c <- aggregate(high~state.name, data=z, FUN=mean)
## Save output
dis.boot[,i] <- a$prej.stdz
dis.boot.above[,i] <- b$above
dis.boot.high[,i] <- c$high
## Create state rankings
state.rank[,i] <- 52-rank(dis.boot[,i])
}
##########################################################################################
rm(list=ls())
##########################################################################################
## BOOTSTRAPS FOR NAES / CCAP COMBINED
##########################################################################################
library(foreign)
library(weights)
## Set RNG seed for replication
set.seed(1977)
## Read in data
ccap.data <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/CCAP/ccap08-clean.csv', stringsAsFactors=F)
naes.data <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/NAES/naes08-online-clean-ALL.csv', stringsAsFactors=F)
naes.data <- naes.data[complete.cases(naes.data$wt.345),]
# Merge state.name in NAES (via fips)
state <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/NAES/08statevars.csv', stringsAsFactors=F)
naes.data <- merge(state, naes.data, by.x='state.fips', by.y='fips', all.x=T, all.y=F)
rm(state)
## Create probability weights (sum to 1)
ccap.data$pweight <- ccap.data$weight / sum(ccap.data$weight)
naes.data$pweight <- naes.data$wt.345 / sum(naes.data$wt.345, na.rm=T)
## Create empty data.frames to save bootstrap results
rank.mean <- data.frame(t01=rep(NA,7), t02=rep(NA,7), t03=rep(NA,7), t04=rep(NA,7),
t05=rep(NA,7), t06=rep(NA,7), t07=rep(NA,7), t08=rep(NA,7), t09=rep(NA,7), t10=rep(NA,7),
t11=rep(NA,7), t12=rep(NA,7), t13=rep(NA,7), t14=rep(NA,7), t15=rep(NA,7), t16=rep(NA,7),
t17=rep(NA,7), t18=rep(NA,7), t19=rep(NA,7), t20=rep(NA,7), t21=rep(NA,7), t22=rep(NA,7),
t23=rep(NA,7), t24=rep(NA,7), t25=rep(NA,7))
dis.boot <- matrix(data=NA, nrow=51, ncol=N)
dis.boot.above <- matrix(data=NA, nrow=51, ncol=N)
dis.boot.high <- matrix(data=NA, nrow=51, ncol=N)
state.rank <- matrix(data=NA, nrow=51, ncol=N)
N <- 20
J <- unique(ccap.data$state)
for (i in 1:N){
## Sample data in blocks by state
ccap.boot <- ccap.data[1,]
naes.boot <- naes.data[1,]
for (j in J){
ccap.state <- ccap.data[ccap.data$state==j,]
num <- table(ccap.data$state[ccap.data$state==j])
ccap.sample <- ccap.state[sample(1:nrow(ccap.state), size=num, replace=T,
prob=ccap.data$pweight[ccap.data$state==j]), ]
ccap.boot <- rbind(ccap.boot, ccap.sample)
naes.state <- naes.data[naes.data$state.name==j,]
num <- table(naes.data$state.name[naes.data$state.name==j])
naes.sample <- naes.state[sample(1:nrow(naes.state), size=num, replace=T,
prob=naes.data$pweight[naes.data$state.name==j]), ]
naes.boot <- rbind(naes.boot, naes.sample)
}
ccap.boot <- ccap.boot[-1,]
naes.boot <- naes.boot[-1,]
#####
##### Prejudice from CCAP #####
#####
## Subset to Asian, Hispanic, or White (N=17,825)
ccap.boot <- ccap.boot[ccap.boot$race=='White' | ccap.boot$race=='Asian' | ccap.boot$race=='Hispanic',]
## Create own group stereotype variables
ccap.boot$lazy.own <- ifelse(ccap.boot$race=='Asian', ccap.boot$lazy.asian,
ifelse(ccap.boot$race=='Hispanic', ccap.boot$lazy.hisp,
ifelse(ccap.boot$race=='White', ccap.boot$lazy.white, NA)))
ccap.boot$intel.own <- ifelse(ccap.boot$race=='Asian', ccap.boot$intel.asian,
ifelse(ccap.boot$race=='Hispanic', ccap.boot$intel.hisp,
ifelse(ccap.boot$race=='White', ccap.boot$intel.white, NA)))
## Calculate the difference between own group and black score
ccap.boot$lazy <- ccap.boot$lazy.own - ccap.boot$lazy.black
ccap.boot$intel <- ccap.boot$intel.own - ccap.boot$intel.black
## Aggregate the differences
ccap.boot$prejudice <- ccap.boot$lazy + ccap.boot$intel
## Standardize prejudice measure
ccap.boot$prej.stdz <- stdz(ccap.boot$prejudice)
#####
##### Prejudice from NAES #####
#####
## Subset to non black (N=19,325)
naes.boot <- naes.data[naes.data$race!=2,]
## Calculate the difference between own group and black score
naes.boot$hw <- naes.boot$work.oth - naes.boot$work.own
naes.boot$intel <- naes.boot$intel.oth - naes.boot$intel.own
naes.boot$trust <- naes.boot$trust.oth - naes.boot$trust.own
## Aggregate the three dummies
naes.boot$prejudice <- naes.boot$hw + naes.boot$intel + naes.boot$trust
## Standardize prejudice measure
naes.boot$prej.stdz <- stdz(naes.boot$prejudice)
## Combine prejudice measures
z <- data.frame(state.name=c(ccap.boot$state, naes.boot$state.name),
prej.stdz=c(ccap.boot$prej.stdz, naes.boot$prej.stdz))
## Proportion above ___
z$above <- ifelse(z$prej.stdz > mean(z$prej.stdz, na.rm=T), 1, 0)
z$high <- ifelse(z$prej.stdz > (mean(z$prej.stdz, na.rm=T) + sd(z$prej.stdz, na.rm=T)), 1, 0)
## Aggregate by state
a <- aggregate(prej.stdz~state.name, data=z, FUN=mean)
b <- aggregate(above~state.name, data=z, FUN=mean)
c <- aggregate(high~state.name, data=z, FUN=mean)
## Save output
dis.boot[,i] <- a$prej.stdz
dis.boot.above[,i] <- b$above
dis.boot.high[,i] <- c$high
## Create state rankings
state.rank[,i] <- 52-rank(dis.boot[,i])
}
##########################################################################################
a
dis.boot
dis.boot.above
rm(list=ls())
##########################################################################################
## BOOTSTRAPS FOR NAES / CCAP COMBINED
##########################################################################################
library(foreign)
library(weights)
## Set RNG seed for replication
set.seed(1977)
## Read in data
ccap.data <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/CCAP/ccap08-clean.csv', stringsAsFactors=F)
naes.data <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/NAES/naes08-online-clean-ALL.csv', stringsAsFactors=F)
naes.data <- naes.data[complete.cases(naes.data$wt.345),]
# Merge state.name in NAES (via fips)
state <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/NAES/08statevars.csv', stringsAsFactors=F)
naes.data <- merge(state, naes.data, by.x='state.fips', by.y='fips', all.x=T, all.y=F)
rm(state)
## Create probability weights (sum to 1)
ccap.data$pweight <- ccap.data$weight / sum(ccap.data$weight)
naes.data$pweight <- naes.data$wt.345 / sum(naes.data$wt.345, na.rm=T)
## Create empty data.frames to save bootstrap results
rank.mean <- data.frame(t01=rep(NA,7), t02=rep(NA,7), t03=rep(NA,7), t04=rep(NA,7),
t05=rep(NA,7), t06=rep(NA,7), t07=rep(NA,7), t08=rep(NA,7), t09=rep(NA,7), t10=rep(NA,7),
t11=rep(NA,7), t12=rep(NA,7), t13=rep(NA,7), t14=rep(NA,7), t15=rep(NA,7), t16=rep(NA,7),
t17=rep(NA,7), t18=rep(NA,7), t19=rep(NA,7), t20=rep(NA,7), t21=rep(NA,7), t22=rep(NA,7),
t23=rep(NA,7), t24=rep(NA,7), t25=rep(NA,7))
dis.boot <- matrix(data=NA, nrow=51, ncol=N)
rm(list=ls())
##########################################################################################
## BOOTSTRAPS FOR NAES / CCAP COMBINED
##########################################################################################
library(foreign)
library(weights)
## Set RNG seed for replication
set.seed(1977)
## Read in data
ccap.data <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/CCAP/ccap08-clean.csv', stringsAsFactors=F)
naes.data <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/NAES/naes08-online-clean-ALL.csv', stringsAsFactors=F)
naes.data <- naes.data[complete.cases(naes.data$wt.345),]
# Merge state.name in NAES (via fips)
state <- read.csv('~/Dropbox/Papers/Elmendorf-Spencer/Data/NAES/08statevars.csv', stringsAsFactors=F)
naes.data <- merge(state, naes.data, by.x='state.fips', by.y='fips', all.x=T, all.y=F)
rm(state)
## Create probability weights (sum to 1)
ccap.data$pweight <- ccap.data$weight / sum(ccap.data$weight)
naes.data$pweight <- naes.data$wt.345 / sum(naes.data$wt.345, na.rm=T)
## Create empty data.frames to save bootstrap results
rank.mean <- data.frame(t01=rep(NA,7), t02=rep(NA,7), t03=rep(NA,7), t04=rep(NA,7),
t05=rep(NA,7), t06=rep(NA,7), t07=rep(NA,7), t08=rep(NA,7), t09=rep(NA,7), t10=rep(NA,7),
t11=rep(NA,7), t12=rep(NA,7), t13=rep(NA,7), t14=rep(NA,7), t15=rep(NA,7), t16=rep(NA,7),
t17=rep(NA,7), t18=rep(NA,7), t19=rep(NA,7), t20=rep(NA,7), t21=rep(NA,7), t22=rep(NA,7),
t23=rep(NA,7), t24=rep(NA,7), t25=rep(NA,7))
N <- 20
dis.boot <- matrix(data=NA, nrow=51, ncol=N)
dis.boot.above <- matrix(data=NA, nrow=51, ncol=N)
dis.boot.high <- matrix(data=NA, nrow=51, ncol=N)
state.rank <- matrix(data=NA, nrow=51, ncol=N)
J <- unique(ccap.data$state)
for (i in 1:N){
## Sample data in blocks by state
ccap.boot <- ccap.data[1,]
naes.boot <- naes.data[1,]
for (j in J){
ccap.state <- ccap.data[ccap.data$state==j,]
num <- table(ccap.data$state[ccap.data$state==j])
ccap.sample <- ccap.state[sample(1:nrow(ccap.state), size=num, replace=T,
prob=ccap.data$pweight[ccap.data$state==j]), ]
ccap.boot <- rbind(ccap.boot, ccap.sample)
naes.state <- naes.data[naes.data$state.name==j,]
num <- table(naes.data$state.name[naes.data$state.name==j])
naes.sample <- naes.state[sample(1:nrow(naes.state), size=num, replace=T,
prob=naes.data$pweight[naes.data$state.name==j]), ]
naes.boot <- rbind(naes.boot, naes.sample)
}
ccap.boot <- ccap.boot[-1,]
naes.boot <- naes.boot[-1,]
#####
##### Prejudice from CCAP #####
#####
## Subset to Asian, Hispanic, or White (N=17,825)
ccap.boot <- ccap.boot[ccap.boot$race=='White' | ccap.boot$race=='Asian' | ccap.boot$race=='Hispanic',]
## Create own group stereotype variables
ccap.boot$lazy.own <- ifelse(ccap.boot$race=='Asian', ccap.boot$lazy.asian,
ifelse(ccap.boot$race=='Hispanic', ccap.boot$lazy.hisp,
ifelse(ccap.boot$race=='White', ccap.boot$lazy.white, NA)))
ccap.boot$intel.own <- ifelse(ccap.boot$race=='Asian', ccap.boot$intel.asian,
ifelse(ccap.boot$race=='Hispanic', ccap.boot$intel.hisp,
ifelse(ccap.boot$race=='White', ccap.boot$intel.white, NA)))
## Calculate the difference between own group and black score
ccap.boot$lazy <- ccap.boot$lazy.own - ccap.boot$lazy.black
ccap.boot$intel <- ccap.boot$intel.own - ccap.boot$intel.black
## Aggregate the differences
ccap.boot$prejudice <- ccap.boot$lazy + ccap.boot$intel
## Standardize prejudice measure
ccap.boot$prej.stdz <- stdz(ccap.boot$prejudice)
#####
##### Prejudice from NAES #####
#####
## Subset to non black (N=19,325)
naes.boot <- naes.data[naes.data$race!=2,]
## Calculate the difference between own group and black score
naes.boot$hw <- naes.boot$work.oth - naes.boot$work.own
naes.boot$intel <- naes.boot$intel.oth - naes.boot$intel.own
naes.boot$trust <- naes.boot$trust.oth - naes.boot$trust.own
## Aggregate the three dummies
naes.boot$prejudice <- naes.boot$hw + naes.boot$intel + naes.boot$trust
## Standardize prejudice measure
naes.boot$prej.stdz <- stdz(naes.boot$prejudice)
## Combine prejudice measures
z <- data.frame(state.name=c(ccap.boot$state, naes.boot$state.name),
prej.stdz=c(ccap.boot$prej.stdz, naes.boot$prej.stdz))
## Proportion above ___
z$above <- ifelse(z$prej.stdz > mean(z$prej.stdz, na.rm=T), 1, 0)
z$high <- ifelse(z$prej.stdz > (mean(z$prej.stdz, na.rm=T) + sd(z$prej.stdz, na.rm=T)), 1, 0)
## Aggregate by state
a <- aggregate(prej.stdz~state.name, data=z, FUN=mean)
b <- aggregate(above~state.name, data=z, FUN=mean)
c <- aggregate(high~state.name, data=z, FUN=mean)
## Save output
dis.boot[,i] <- a$prej.stdz
dis.boot.above[,i] <- b$above
dis.boot.high[,i] <- c$high
## Create state rankings
state.rank[,i] <- 52-rank(dis.boot[,i])
print(i)
}
dis.boot
doug <- data.frame(state.name = unique(ccap.data$state.name))
doug
doug <- data.frame(state.name = unique(ccap.data$state))
doug
doug <- data.frame(state.name = sort(unique(ccap.data$state)))
doug
?apply
doug <- data.frame(state.name = sort(unique(ccap.data$state)),
prej = apply(dis.boot, 2, FUN=median),
low = apply(dis.boot, 2, FUN=quantile, prob=0.025),
high = apply(dis.boot, 2, FUN=quantile, prob=0.975)
)
doug <- data.frame(state.name = sort(unique(ccap.data$state)),
prej = apply(dis.boot, 1, FUN=median),
low = apply(dis.boot, 1, FUN=quantile, prob=0.025),
high = apply(dis.boot, 1, FUN=quantile, prob=0.975)
)
doug
sapply(doug, class)
doug$section.5 <- 2
doug$section.5[c(5,10,23,30,34,42)] <- 1 # partially covered states
doug$section.5[c(1:3,11,19,25,41,44,47)] <- 0 # fully covered states
doug <- data.frame(state.name = sort(unique(ccap.data$state)),
prej = apply(dis.boot, 1, FUN=median),
low = apply(dis.boot, 1, FUN=quantile, prob=0.025),
high = apply(dis.boot, 1, FUN=quantile, prob=0.975)
)
# Section 5
doug$section.5 <- 2
doug$section.5[c(5,10,23,30,34,42)] <- 1 # partially covered states
doug$section.5[c(1:3,11,19,25,41,44,47)] <- 0 # fully covered states
library(ggplot2)
doug$state <- reorder(as.character(doug$state.name), doug$prej)
p <- qplot(prej, state, data=doug, shape=as.factor(section.5), col=as.factor(section.5)) +
xlim(c(-0.5,0.5)) + ggtitle('Average prejudice score \n (bootstrap)') + ylab('') +
xlab('Average difference between scores for own vs. black') +
geom_vline(xintercept=mean(doug$prej), linetype=2, colour="black") +
scale_shape_manual("Section 5", values=c(19, 1, 19), labels=c("Covered", "Partially covered", "Not covered")) +
scale_colour_manual("Section 5", values=c('firebrick2', 'black', 'black'), labels=c("Covered", "Partially covered", 'Not covered')) +
theme(panel.background=element_rect(fill = "white", colour = "black")) +
theme(axis.text.y=element_text(size=7, colour="gray20"), axis.title.x=element_text(size=10)) + geom_point() +
geom_errorbarh(aes(xmin=doug$low, xmax=doug$high), height=0, size=0.7)
p
p <- qplot(prej, state, data=doug, shape=as.factor(section.5), col=as.factor(section.5)) +
xlim(c(-0.5,0.8)) + ggtitle('Average prejudice score \n (bootstrap)') + ylab('') +
xlab('Average difference between scores for own vs. black') +
geom_vline(xintercept=mean(doug$prej), linetype=2, colour="black") +
scale_shape_manual("Section 5", values=c(19, 1, 19), labels=c("Covered", "Partially covered", "Not covered")) +
scale_colour_manual("Section 5", values=c('firebrick2', 'black', 'black'), labels=c("Covered", "Partially covered", 'Not covered')) +
theme(panel.background=element_rect(fill = "white", colour = "black")) +
theme(axis.text.y=element_text(size=7, colour="gray20"), axis.title.x=element_text(size=10)) + geom_point() +
geom_errorbarh(aes(xmin=doug$low, xmax=doug$high), height=0, size=0.7)
p
source('~/Dropbox/Papers/Elmendorf-Spencer/Data/CCAP Cluster/naes_ccap_boot_3.R')
setwd('~/Dropbox/Papers/Elmendorf-Spencer/Data/elmendorf_spencer_replication/')
library(foreign)
library(weights)
library(ggplot2)
## READ IN CCAP DATA
ccap <- read.csv('data/ccap_08.csv', stringsAsFactors=F)
## ANTI-LATINO STEREOTYPE
## Subset to Asian, Black, or White (N=18,125)
ccap.hisp <- ccap[ccap$race=='White' | ccap$race=='Asian' | ccap$race=='Black',]
## Subset to just Whites (for paper)
#ccap.hisp <- ccap[ccap$race=='White' ,]
## Create own group stereotype variables
ccap.hisp$lazy.own <- ifelse(ccap.hisp$race=='Asian', ccap.hisp$lazy.asian,
ifelse(ccap.hisp$race=='Black', ccap.hisp$lazy.black,
ifelse(ccap.hisp$race=='White', ccap.hisp$lazy.white, NA)))
ccap.hisp$intel.own <- ifelse(ccap.hisp$race=='Asian', ccap.hisp$intel.asian,
ifelse(ccap.hisp$race=='Black', ccap.hisp$intel.black,
ifelse(ccap.hisp$race=='White', ccap.hisp$intel.white, NA)))
## Calculate the difference between own group and Latino score
ccap.hisp$lazy <- ccap.hisp$lazy.own - ccap.hisp$lazy.hisp
ccap.hisp$intel <- ccap.hisp$intel.own - ccap.hisp$intel.hisp
## Aggregate the differences
ccap.hisp$prej.hisp <- ccap.hisp$lazy + ccap.hisp$intel
## Subset to complete cases
ccap.hisp <- ccap.hisp[complete.cases(ccap.hisp$prej.hisp),]
## Normalize measure
ccap.hisp$prej.hisp.stdz <- stdz(ccap.hisp$prej.hisp, weight=ccap.hisp$weight)
##########
## Aggregate by state
latino.mean <- aggregate(prej.hisp~state, data=ccap.hisp, FUN=mean)
## Section 5
latino.mean$section.5 <- 2
latino.mean$section.5[c(5,10,23,30,34,42)] <- 1 # partially covered states
latino.mean$section.5[c(1:3,11,19,25,41,44,47)] <- 0 # fully covered states
## Standard Errors
# SEs by state sigma
sample <- data.frame(table(ccap.hisp$state))
names(sample) <- c('state', 'sample.n')
ssname <- unique(ccap.hisp$state)
latino.mean <- merge(latino.mean, sample)
temp <- NA
for (i in ssname){
temp2 <- sd(ccap.hisp$prej.hisp.stdz[ccap.hisp$state==i], na.rm=T)
temp <- rbind(temp, temp2)
}
mean.se <- data.frame(state=ssname, state.sigma=temp[-1,])
latino.mean <- merge(latino.mean, mean.se)
latino.mean$state.low.68 <- latino.mean$prej.hisp-(latino.mean$state.sigma/sqrt(latino.mean$sample.n))
latino.mean$state.high.68 <- latino.mean$prej.hisp+(latino.mean$state.sigma/sqrt(latino.mean$sample.n))
latino.mean$state.low.95 <- latino.mean$prej.hisp-(2*latino.mean$state.sigma/sqrt(latino.mean$sample.n))
latino.mean$state.high.95 <- latino.mean$prej.hisp+(2*latino.mean$state.sigma/sqrt(latino.mean$sample.n))
#########################################################################################
latino.mean$state.order <- reorder(latino.mean$state, latino.mean$prej.hisp)
p.mean <- qplot(prej.hisp, state.order, data=latino.mean, shape=as.factor(section.5), col=as.factor(section.5)) +
xlim(c(-.5, 2)) + ggtitle('Anti-Latino stereotyping') + ylab("") +
xlab("Average difference between stereotype of \n one's own race and Latinos") +
geom_vline(xintercept=mean(latino.mean$prej.hisp), linetype=2, colour="black") +
scale_shape_manual("Section 4", values=c(19, 1, 19), labels=c("Covered", "Partially covered", "Not covered")) +
scale_colour_manual("Section 4", values=c('firebrick2', 'black', 'black'), labels=c("Covered", "Partially covered", 'Not covered')) +
theme(panel.background=element_rect(fill = "white", colour = "black")) +
theme(axis.text.y=element_text(size=7, colour="gray20"), axis.title.x=element_text(size=10)) + geom_point() +
geom_errorbarh(aes(xmin=latino.mean$state.low.95, xmax=latino.mean$state.high.95), height=0, size=0.4)
# theme(legend.position=c(0,1), legend.justification=c(0,1), legend.text=element_text(size=8), legend.title=element_text(size=8))
p.mean
